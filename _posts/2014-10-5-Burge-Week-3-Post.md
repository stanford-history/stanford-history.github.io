#Week 3 Readings and Discussion Questions

##Blog Post
  
  A lot of the data I work with come from outside sources and are organized with varying attention to detail.  While this information rarely comes sorted into a digital database I do encounter the occasional spreadsheet or Excel file of half-jumbled information.  In these instances, I can definitely see the utility of something like OpenRefine in my work.  The ability to refine raw data so that it is more receptive to analysis, and to hammer out inconsistencies and duplicates difficult to discern manually, would be a huge asset in these situations.
  
  I will say that I did not find the format of OpenRefine intuitive.  The difference between viewing in rows and records, for example, made sense for the purposes of the tutorial, but I was confused as to what this would mean for other usages of the application.  Additionally, the real power of OpenRefine seems to be in the ability to "transform" cells, a function that requires learning a separate set of commands unique to the program (or at least unknown to me).  I also encountered a couple technical errors when trying to load OpenRefine, and had to reboot my computer and start over my project a number of times.
  
  Finally, as alluded to in the tutorial, it seems that it would be easy to get over-eager as a researcher and refine some of this material into categories that do not go together.  Separate terms that appear superficially to refer to the same thing may in fact have different nuances or have been input under different information regimes, and there may be information visible to us only when the data is in this "unrefined" state.  This a problem I am especially sensitive to as I often work in languages that are not my own, and have to second-guess my own sense of when words mean exactly the same thing and when they actually have a nuanced difference.
  
  That being said, the next time I do encounter a large data set like this I will definitely see what I can accomplish with OpenRefine.  This is clearly a powerful tool.
  
##Discussion Questions
  
  1. How versatile is OpenRefine with data formats?  I assume something like an Excel file would be no problem, but what about data from foreign applications or websites?
  
  2. Digital preservation is in many ways more vulnerable than physical preservation, but it also, [as the late Roy Rosenzweig pointed out in 2003](http://chnm.gmu.edu/essays-on-history-new-media/essays/?essayid=6), threatens historians with "unheard-of historical abundance."  Beyond working more in the mold of data analysis or sociology, as Rosenzweig alludes to, what other ways might historians find of making sense of this glut of information?
  
  3. Marc J. Dunkelman argues that the parameters of academic questions in the humanities and social sciences [are increasingly shaped by the availability of data](http://chronicle.com/blogs/conversation/2014/08/19/what-data-cant-convey/).  For the discipline of history, to what extent is this a new phenomenon?  Haven't historians always relied on evidence to make their claims -- and wasn't the heyday of data-driven history during the zenith of social history in the 1960s and 70s?  Or is the kind of evidence we rely on changing in a new and different way?
