#Week 4 Blog Post and Discussion Questions
  
##Blog Post
To get started on Voyant Tools I visited the online Japanese literature archive
[Aozora Bunko](http://www.aozora.gr.jp/), a repository of full-text
Japanese novels, essays, and poetry.  Most of my research uses Korean newspaper articles and government documents, but I chose Aozora Bunko because of the availability of html documents that Voyant Tools could scan and input (most of the archives I work on have only scanned images, or proprietary text databases with limited searchability). 
  
I decided to profile the corpus of turn-of-the-century author Natsume Soseki, most famous for his novels Kokoro and Wagahai wa neko de aru (I am a cat).  Aozora Bunko has over 100 of these works; I provided links to 102 documents, trying to omit duplicates or writings that appear both as single volumes and as separate installments.
  
I didn't find much surprising when I looked at Natsume's corpus.  We get a lot of the word 猫 (neko; cat) and for some reason the character 大 (big) appears frequently.  
  
For comparison I provided links to about 30 of the works of Mori Ogai, an author who was Natsume's rough contemporary.  These 30 works represent about one quarter of the Mori works available on Aozora Bunko.  I can't say I found much of worth notice here either, but one phenomenon did stand out to me -- the phrase である/de aru, or the Japanese copula meaning "to be," is a formulation that is perfectly normal in writing but somewhat outdated and pretentious when used in speech.  Natsume famously used this to comedic effect in his title phrase 吾輩は猫である/"wagahai wa neko de aru," which was meant to parody the haughty demeanor of his central cat character.  Interestingly, the phrase "de aru" appears across almost all of Natsume's works with much greater frequency than Mori's.
  
I'm not sure why this would be, but I do have one guess: Mori Ogai makes more use of dialogue than Natsume Soseki, and in dialogue such a phrase would be out of place. Additionally, many of the Natsume works on Aozora Bunko are essays, and in expository writing one would expect to see the "de aru" phrase much more often.
  
The fact is, though, that I'm not sure what this means, or why the distribution should be so large (Voyant gives me a difference value of 20, which I'm not sure how to interpret except that it's far larger than any of the other difference values).  There are other confounding variables that may come down to style, or even regional affectation.  

Speaking of which, the "de aru" discrepancy almost certainly isn't the most interesting thing about this data.  This is a time period in which a central Tokyo-based literati were coming into existence in Japan, and many writers were simultaneously working to master a metropolitan vocabulary and experimenting with colloquial speech in their works, so there's probably a host of interesting corrolations here that someone more familiar with these writers would be able to pick up on.  Megan R. Brett stresses in her [article on topic modeling](http://journalofdigitalhumanities.org/2-1/topic-modeling-a-basic-introduction-by-megan-r-brett/) that scholars need to be familiar with an archive before digital analysis is possible, and I am certainly no expert in Japanese literature -- though I can see the power of Voyant Tools to someone who is. 
  
##Discussion Questions
  
1. Using Voyant reminded me of a recent study undertaken by a Stanford sociologist who works on Korea; in his book he mined newspaper archives to determine the frequency of topics having to do with issues of national identity and culture, versus those concerning more institutional and political issues such as education reform and the welfare of the nation vis-a-vis foreign powers.  Through this frequentist analysis, he was able to reveal two periods in which Korea veered away from civic (state and institution-based) nationalism and toward ethnic (race and culture-based) nationalism.  This study was powerful in its ability to uncover these rhetorical shifts.  Through this methodology, however, it was impossible to determine *why* these shifts had occurred, or even if the data is reflecting an actual shift in national paradigms.  Does this invalidate a frequentist approach?  To my mind these data are still useful, but do we have any tools at our disposal other than conventional historiographical approaches when it comes to interpreting them?
  
2. In [his article on MALLET](http://sappingattention.blogspot.com/2012/11/when-you-have-mallet-everything-looks.html), Ben Schmidt highlights the danger of drawing associations between sets of data that are fundamentally unrelated when using topic modeling software.  Is there a danger in the digital humanities -- or in data analysis generally -- of scholars losing track of their own subject matter, and trusting too much in algorithms and statistical modeling?  Is this a new danger, or has it been with history since at least as long as social history?  Is this risk heightened or diminished as we move to larger and larger sample sizes?
  
3. How transparent should scholars make their methodologies when presenting data derived from topic modeling programs?  How deeply should historians themselves understand the technology they work with?
