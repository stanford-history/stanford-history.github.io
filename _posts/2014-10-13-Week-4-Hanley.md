---
title: Week 4 Reflection
date: 2014-10-13
author: JAmes Hanley
layout: post
---

#BLOG POST:

I have to admit, working through some of these articles (although they were all relatively short) was difficult for me. Unlike one of the authors, I would be completely lost in “25-dimensional simplexes”. Basically, the more technical, the more it felt like banging my head against the wall. I had this sensation most with Miriam Posner’s article on basic techniques, and the articles she linked to.

I suppose this is the nitty-gritty of digital humanities. I don’t see much use for it in literature – after all, isn’t the art of writing nothing but the careful and deliberate use language? I got this feeling especially after reading Ted Underwood’s analysis of poetry; I simply couldn’t see what use a tool like this could be. 

However, for historical investigations (for which literature may very well be a source), I think it does make sense. By far my favorite article was Benjanin Schmidt’s “When you have a MALLET, everything looks like a nail.” He finds an idiosyncratic use for LDA, mapping into according to geospatial coordinates. He points out how this gives a stable, intuitive reference frame to topics, which would otherwise simply float about one another (“word clouds”). In one of his projections, we may observe an Atlantic-European trade, as well as one between Hawaii and the Pacific Rim. While I have no idea how or why such a projection would come to be, he claims it is essentially meaningless (“I might...start to tell a just-so story about how [they] really are connected. They are; but so is everything else”).

He extends this observation to point out that LDA, while being an undoubtedly powerful tool, ultimately behaves like a “bad research assistant.” He chides the arguments built upon it as tenuous, resting not upon experience but on the authority of the technician-interpreter, which  to me means that it fails to contribute to one of digital history’s most urgent tasks: to curate and proffer massive archives of text.

That said, I would like to more about the mathematical principles behind LDA. It sounds like they are a modulation of the Bayesian formula, which, if I am not mistaken, is the basis for nearly all natural language processing.

As for Voyant, I screwed around with Shakespeare’s corpus. One projection I found somewhat suggestive is the use of ‘LORD’ in Hamlet, Macbeth and Julius Caesar. Each had a distinct apex and decline in the use of this word. However, the apex came at different parts of the each play: in Hamlet, the beginning; Macbeth, the middle; Julius Caeser, the end. I found this to be an interesting occasion to meditate upon the word ‘lord’, which is after all “performative” in the sense that its utterance enacts a social or political relation between speaker and audience. In this way, the word acts as an indicator of some “social glue”. Seeing the use of this word rise and/or fall allows us to characterize and compare the three plays accordingly: Hamlet is a story of the established social fabric coming undone; Macbeth, the assertion and demise of a political order; Julius Caesar, the birth of some new social-political form. Regarding the last, I looked closer and saw that the word was being used by various characters liberally amongst themselves (e.g. Brutus to Cassius, Cassius to Brutus), which suggests the shift from monarchy to republicanism.

That said, maybe this particular projection is less a data visualization (in the rigorous sense of datum, something given) than a Rorschach test, giving me space only to expound what I already believe.


#DISCUSSION QUESTIONS:

Were any of you able to get anything out of playing with Voyant? How much do you think tools like this allow you to genuinely discover, as opposed to merely giving pretense to argue for what you already believe?

Can LDA provide a stable basis for _raising questions, formulating hypotheses, and/or demonstrating arguments_?
